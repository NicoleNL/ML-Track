{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd583e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write config file\n",
    "import json\n",
    "json_path = \"C:/Users/nchong/OneDrive - Intel Corporation/Documents/Debug Similarity Analytics and Bucketization Framework/General/\"\n",
    "path = \"C:/Users/nchong/OneDrive - Intel Corporation/Documents/Debug Similarity Analytics and Bucketization Framework/General/Sample json output/HSD ES Raw Data/team1/\"\n",
    "\n",
    "config = {\n",
    "    \"DataLoading\": {\"path\": path, \"start_date\": None,\"stop_date\":None},\n",
    "    \"df_manipulation\": {\"col_selection\": None,\"keep\": None,\"subset\":None},    \n",
    "    \"word_contractions\": {\"wordcont\": True}\n",
    "    \n",
    "    \n",
    "    \n",
    "#     \"Supervised\":\n",
    "#     \"Unsupervised\":\n",
    "#     \"SimilarityMetrics\"\n",
    "}\n",
    "\n",
    "with open(json_path+'config.json', 'w') as f:\n",
    "    json.dump(config,f,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74fa07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read config file and call the other functions\n",
    "def main(json_path):\n",
    "    \n",
    "    import json     \n",
    "    \n",
    "    with open(json_path+'config.json') as config_file:\n",
    "        data = json.load(config_file)\n",
    "    \n",
    "    #data loading \n",
    "    path = data[\"DataLoading\"]['path']  \n",
    "    start_date = data[\"DataLoading\"]['start_date']\n",
    "    stop_date = data[\"DataLoading\"]['stop_date']\n",
    "    df = data_loading(path=path,start_date=start_date,stop_date=stop_date)\n",
    "            \n",
    "    #data preprocessing       \n",
    "    col_selection = data[\"df_manipulation\"]['col_selection'] \n",
    "    keep = data[\"df_manipulation\"]['keep'] \n",
    "    subset = data[\"df_manipulation\"]['subset']\n",
    "    df = df_manipulation(df,col_selection=col_selection,keep=keep,subset=subset)\n",
    "    display(df)\n",
    "    \n",
    "    \n",
    "    method #1\n",
    "    [\"title\",\"Desc\",\"comment\"]\n",
    "    \n",
    "    wordcont = data[\"df_manipulation\"][\"word_contractions\"]\n",
    "    if wordcont:\n",
    "        df[\"title_cont\"] = [word_contractions(text) for text in df[\"title\"]]\n",
    "        df[\"desc_cont\"] = [word_contractions(text) for text in df[\"desc\"]]\n",
    "        df[\"comment_cont\"] = [word_contractions(text) for text in df[\"comment\"]\n",
    "    \n",
    "    method #2\n",
    "    df (title,desc,comments) -> df(title,desc,comments) + df (title_cont,desc_cont,comments_cont)\n",
    "    df (title,desc,comments) -> concat df(title,desc,comments) [df1]\n",
    "                              columnbind(df,df1)\n",
    "                              \n",
    "    #supervised learning\n",
    "    #unsupervised learning\n",
    "    #similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ee69fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files read: ['C:/Users/nchong/OneDrive - Intel Corporation/Documents/Debug Similarity Analytics and Bucketization Framework/General/Sample json output/HSD ES Raw Data/team1/(2021-08-25)1_firstSet_1.json', 'C:/Users/nchong/OneDrive - Intel Corporation/Documents/Debug Similarity Analytics and Bucketization Framework/General/Sample json output/HSD ES Raw Data/team1/(2021-08-25)3_secondSet_1.json', 'C:/Users/nchong/OneDrive - Intel Corporation/Documents/Debug Similarity Analytics and Bucketization Framework/General/Sample json output/HSD ES Raw Data/team1/(2021-10-11)3_secondSet_1.json']\n",
      "Shape of df before manipulation: (2712, 15)\n",
      "Shape of df after selecting columns: (2712, 15)\n",
      "Number of null values in df:\n",
      " id                   0\n",
      "title             1808\n",
      "description          0\n",
      "comments          1808\n",
      "updated_date         0\n",
      "hierarchy_id         0\n",
      "rev                  0\n",
      "tenant               0\n",
      "subject              0\n",
      "is_current           0\n",
      "hierarchy_path       0\n",
      "parent_id            0\n",
      "record_type          0\n",
      "row_num              0\n",
      "file                 0\n",
      "dtype: int64\n",
      "Number of null values in df after NA imputation:\n",
      " id                0\n",
      "title             0\n",
      "description       0\n",
      "comments          0\n",
      "updated_date      0\n",
      "hierarchy_id      0\n",
      "rev               0\n",
      "tenant            0\n",
      "subject           0\n",
      "is_current        0\n",
      "hierarchy_path    0\n",
      "parent_id         0\n",
      "record_type       0\n",
      "row_num           0\n",
      "file              0\n",
      "dtype: int64\n",
      "Number of duplicates in the df: 0\n",
      "Shape of df after manipulation: (2712, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>comments</th>\n",
       "      <th>updated_date</th>\n",
       "      <th>hierarchy_id</th>\n",
       "      <th>rev</th>\n",
       "      <th>tenant</th>\n",
       "      <th>subject</th>\n",
       "      <th>is_current</th>\n",
       "      <th>hierarchy_path</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>record_type</th>\n",
       "      <th>row_num</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1308651592</td>\n",
       "      <td>provide method to update GIO fields from git r...</td>\n",
       "      <td>Please provide a way to update GIO fields from...</td>\n",
       "      <td>++++1562123662 fbakhda\\nHi @Panceac, Cornel Eu...</td>\n",
       "      <td>2021-07-21 12:30:31.387</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>iot_platf</td>\n",
       "      <td>support</td>\n",
       "      <td>1</td>\n",
       "      <td>/1201559436/1208431055/1308651592/</td>\n",
       "      <td>1208431055</td>\n",
       "      <td>parent</td>\n",
       "      <td>1</td>\n",
       "      <td>(2021-08-25)1_firstSet_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1308671310</td>\n",
       "      <td>Test suite execution terminates before executi...</td>\n",
       "      <td>&lt;p&gt;Test suite execution finished before execut...</td>\n",
       "      <td>++++1361513318 cmoala\\nsys_tsdval@GL-IAF1-V-S0...</td>\n",
       "      <td>2021-05-04 09:30:00.320</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>iot_platf</td>\n",
       "      <td>support</td>\n",
       "      <td>1</td>\n",
       "      <td>/1201559436/1208431055/1308671310/</td>\n",
       "      <td>1208431055</td>\n",
       "      <td>parent</td>\n",
       "      <td>2</td>\n",
       "      <td>(2021-08-25)1_firstSet_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1308673361</td>\n",
       "      <td>Cloning defects from another test cycle is not...</td>\n",
       "      <td>&lt;p&gt;I am trying to clone defects from another t...</td>\n",
       "      <td>++++1361514315 cmoala\\nObserved that only impl...</td>\n",
       "      <td>2021-05-20 11:47:18.927</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>iot_platf</td>\n",
       "      <td>support</td>\n",
       "      <td>1</td>\n",
       "      <td>/1201559436/1208431055/1308673361/</td>\n",
       "      <td>1208431055</td>\n",
       "      <td>parent</td>\n",
       "      <td>3</td>\n",
       "      <td>(2021-08-25)1_firstSet_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1507656633</td>\n",
       "      <td>[Testing Only] this is enhancement only</td>\n",
       "      <td>Retest some function again.</td>\n",
       "      <td></td>\n",
       "      <td>2020-03-13 10:16:18.703</td>\n",
       "      <td></td>\n",
       "      <td>31</td>\n",
       "      <td>iot_platf</td>\n",
       "      <td>support</td>\n",
       "      <td>1</td>\n",
       "      <td>/1201559436/1208431055/1507656633/</td>\n",
       "      <td>1208431055</td>\n",
       "      <td>parent</td>\n",
       "      <td>4</td>\n",
       "      <td>(2021-08-25)1_firstSet_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1507656638</td>\n",
       "      <td>[Testing Only] this is consultation only</td>\n",
       "      <td>enter the support needed at here ...</td>\n",
       "      <td>++++1661488832 prajput\\nHSDES testing. Please ...</td>\n",
       "      <td>2020-06-01 09:49:55.913</td>\n",
       "      <td></td>\n",
       "      <td>19</td>\n",
       "      <td>iot_platf</td>\n",
       "      <td>support</td>\n",
       "      <td>1</td>\n",
       "      <td>/1201559436/1208431055/1507656638/</td>\n",
       "      <td>1208431055</td>\n",
       "      <td>parent</td>\n",
       "      <td>5</td>\n",
       "      <td>(2021-08-25)1_firstSet_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>22012641037</td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;&lt;span style=\"font-size: 12.18px;\"&gt;Hello,&amp;...</td>\n",
       "      <td></td>\n",
       "      <td>2021-03-26 13:19:20.430</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>iot_platf</td>\n",
       "      <td>support</td>\n",
       "      <td>1</td>\n",
       "      <td>/1201559436/1208431055/22012641037/</td>\n",
       "      <td>1208431055</td>\n",
       "      <td>parent</td>\n",
       "      <td>900</td>\n",
       "      <td>(2021-10-11)3_secondSet_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>22012645565</td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;Hi Gio Team,&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;Thank you f...</td>\n",
       "      <td></td>\n",
       "      <td>2021-05-20 13:03:09.327</td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "      <td>iot_platf</td>\n",
       "      <td>support</td>\n",
       "      <td>1</td>\n",
       "      <td>/1201559436/1208431055/22012645565/</td>\n",
       "      <td>1208431055</td>\n",
       "      <td>parent</td>\n",
       "      <td>901</td>\n",
       "      <td>(2021-10-11)3_secondSet_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>22012704243</td>\n",
       "      <td></td>\n",
       "      <td>&lt;div&gt;The schedule test suite allow for the use...</td>\n",
       "      <td></td>\n",
       "      <td>2021-04-26 10:04:12.410</td>\n",
       "      <td></td>\n",
       "      <td>9</td>\n",
       "      <td>iot_platf</td>\n",
       "      <td>support</td>\n",
       "      <td>1</td>\n",
       "      <td>/1201559436/1208431055/22012704243/</td>\n",
       "      <td>1208431055</td>\n",
       "      <td>parent</td>\n",
       "      <td>902</td>\n",
       "      <td>(2021-10-11)3_secondSet_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>22012765885</td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;Hi Gio Team,&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;Thank you f...</td>\n",
       "      <td></td>\n",
       "      <td>2021-06-30 00:35:58.927</td>\n",
       "      <td></td>\n",
       "      <td>14</td>\n",
       "      <td>iot_platf</td>\n",
       "      <td>support</td>\n",
       "      <td>1</td>\n",
       "      <td>/1201559436/1208431055/22012765885/</td>\n",
       "      <td>1208431055</td>\n",
       "      <td>parent</td>\n",
       "      <td>903</td>\n",
       "      <td>(2021-10-11)3_secondSet_1.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>22013190829</td>\n",
       "      <td></td>\n",
       "      <td>&lt;p&gt;Converting to enhancement...&lt;/p&gt;&lt;p&gt;&lt;br /&gt;&lt;/...</td>\n",
       "      <td></td>\n",
       "      <td>2021-07-13 15:41:16.507</td>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "      <td>iot_platf</td>\n",
       "      <td>support</td>\n",
       "      <td>1</td>\n",
       "      <td>/1201559436/1208431055/22013190829/</td>\n",
       "      <td>1208431055</td>\n",
       "      <td>parent</td>\n",
       "      <td>904</td>\n",
       "      <td>(2021-10-11)3_secondSet_1.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2712 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                              title  \\\n",
       "0     1308651592  provide method to update GIO fields from git r...   \n",
       "1     1308671310  Test suite execution terminates before executi...   \n",
       "2     1308673361  Cloning defects from another test cycle is not...   \n",
       "3     1507656633            [Testing Only] this is enhancement only   \n",
       "4     1507656638           [Testing Only] this is consultation only   \n",
       "..           ...                                                ...   \n",
       "899  22012641037                                                      \n",
       "900  22012645565                                                      \n",
       "901  22012704243                                                      \n",
       "902  22012765885                                                      \n",
       "903  22013190829                                                      \n",
       "\n",
       "                                           description  \\\n",
       "0    Please provide a way to update GIO fields from...   \n",
       "1    <p>Test suite execution finished before execut...   \n",
       "2    <p>I am trying to clone defects from another t...   \n",
       "3                          Retest some function again.   \n",
       "4                 enter the support needed at here ...   \n",
       "..                                                 ...   \n",
       "899  <div><span style=\"font-size: 12.18px;\">Hello,&...   \n",
       "900  <p>Hi Gio Team,</p><p><br /></p><p>Thank you f...   \n",
       "901  <div>The schedule test suite allow for the use...   \n",
       "902  <p>Hi Gio Team,</p><p><br /></p><p>Thank you f...   \n",
       "903  <p>Converting to enhancement...</p><p><br /></...   \n",
       "\n",
       "                                              comments  \\\n",
       "0    ++++1562123662 fbakhda\\nHi @Panceac, Cornel Eu...   \n",
       "1    ++++1361513318 cmoala\\nsys_tsdval@GL-IAF1-V-S0...   \n",
       "2    ++++1361514315 cmoala\\nObserved that only impl...   \n",
       "3                                                        \n",
       "4    ++++1661488832 prajput\\nHSDES testing. Please ...   \n",
       "..                                                 ...   \n",
       "899                                                      \n",
       "900                                                      \n",
       "901                                                      \n",
       "902                                                      \n",
       "903                                                      \n",
       "\n",
       "                updated_date hierarchy_id rev     tenant  subject is_current  \\\n",
       "0    2021-07-21 12:30:31.387                8  iot_platf  support          1   \n",
       "1    2021-05-04 09:30:00.320               11  iot_platf  support          1   \n",
       "2    2021-05-20 11:47:18.927                9  iot_platf  support          1   \n",
       "3    2020-03-13 10:16:18.703               31  iot_platf  support          1   \n",
       "4    2020-06-01 09:49:55.913               19  iot_platf  support          1   \n",
       "..                       ...          ...  ..        ...      ...        ...   \n",
       "899  2021-03-26 13:19:20.430               11  iot_platf  support          1   \n",
       "900  2021-05-20 13:03:09.327               11  iot_platf  support          1   \n",
       "901  2021-04-26 10:04:12.410                9  iot_platf  support          1   \n",
       "902  2021-06-30 00:35:58.927               14  iot_platf  support          1   \n",
       "903  2021-07-13 15:41:16.507               16  iot_platf  support          1   \n",
       "\n",
       "                          hierarchy_path   parent_id record_type row_num  \\\n",
       "0     /1201559436/1208431055/1308651592/  1208431055      parent       1   \n",
       "1     /1201559436/1208431055/1308671310/  1208431055      parent       2   \n",
       "2     /1201559436/1208431055/1308673361/  1208431055      parent       3   \n",
       "3     /1201559436/1208431055/1507656633/  1208431055      parent       4   \n",
       "4     /1201559436/1208431055/1507656638/  1208431055      parent       5   \n",
       "..                                   ...         ...         ...     ...   \n",
       "899  /1201559436/1208431055/22012641037/  1208431055      parent     900   \n",
       "900  /1201559436/1208431055/22012645565/  1208431055      parent     901   \n",
       "901  /1201559436/1208431055/22012704243/  1208431055      parent     902   \n",
       "902  /1201559436/1208431055/22012765885/  1208431055      parent     903   \n",
       "903  /1201559436/1208431055/22013190829/  1208431055      parent     904   \n",
       "\n",
       "                               file  \n",
       "0     (2021-08-25)1_firstSet_1.json  \n",
       "1     (2021-08-25)1_firstSet_1.json  \n",
       "2     (2021-08-25)1_firstSet_1.json  \n",
       "3     (2021-08-25)1_firstSet_1.json  \n",
       "4     (2021-08-25)1_firstSet_1.json  \n",
       "..                              ...  \n",
       "899  (2021-10-11)3_secondSet_1.json  \n",
       "900  (2021-10-11)3_secondSet_1.json  \n",
       "901  (2021-10-11)3_secondSet_1.json  \n",
       "902  (2021-10-11)3_secondSet_1.json  \n",
       "903  (2021-10-11)3_secondSet_1.json  \n",
       "\n",
       "[2712 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "json_path = \"C:/Users/nchong/OneDrive - Intel Corporation/Documents/Debug Similarity Analytics and Bucketization Framework/General/\"\n",
    "main(json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028f2344",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f1ecfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading(path,start_date=None,stop_date=None):\n",
    "    '''\n",
    "    Load only files that follow agreed filename format, merge files as single dataframe.\n",
    "    User can choose to \n",
    "    a) Load all json files following the agreed filename format\n",
    "    b) Load only json files from specific dates by adding the start and stop dates (Note: Both start_date and\n",
    "    stop_date must be used together)\n",
    "    \n",
    "    params:\n",
    "    path [string]: path of the files, without filename\n",
    "    \n",
    "    start_date[None/string in YYYY-MM-DD format](optional,default is None): \n",
    "    User can choose to load files starting from start_date\n",
    "    - None: no start_date is provided, all files are loaded\n",
    "    - string in YYYY-MM-DD format: files starting from start_date will be loaded\n",
    "    \n",
    "    stop_date[None/string in YYYY-MM-DD format](optional,default is None): \n",
    "    User can choose to load files until stop_date\n",
    "    - None: no stop_date is provided, all files are loaded\n",
    "    - string in YYYY-MM-DD format: files until stop_date will be loaded\n",
    "    '''\n",
    "    from datetime import datetime,timedelta\n",
    "    import pandas as pd\n",
    "    import glob, os, json\n",
    "    import re\n",
    "    \n",
    "    filenames = os.listdir(path)\n",
    "    file_list=[]\n",
    "    date_list = []\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    if start_date == None and stop_date == None :\n",
    "        for file in filenames:\n",
    "            # search agreed file format pattern in the filename\n",
    "\n",
    "            pattern = r\"^\\(\\d{4}-\\d{2}-\\d{1,2}\\)\\d+\\_\\D+\\_\\d+\\.json$\"\n",
    "\n",
    "            match = re.search(pattern,file)\n",
    "                \n",
    "            #if match is found\n",
    "            if match:\n",
    "                pattern = os.path.join(path, file) #join path with file name\n",
    "                file_list.append(pattern) #list of json files that follow the agreed filename\n",
    "            \n",
    "        print(\"Files read:\",file_list)                   \n",
    "        for file in file_list:\n",
    "            with open(file) as f:\n",
    "                #flatten json into pd dataframe\n",
    "                json_data = pd.json_normalize(json.loads(f.read()))\n",
    "                json_data = pd.DataFrame(json_data)\n",
    "                #label which file each row is from \n",
    "                json_data['file'] = file.rsplit(\"/\", 1)[-1]\n",
    "\n",
    "            df = df.append(json_data)              \n",
    "                \n",
    "    else:\n",
    "        #convert start and stop string to datetime\n",
    "        start = datetime.strptime(start_date, \"%Y-%m-%d\").date()\n",
    "        stop = datetime.strptime(stop_date, \"%Y-%m-%d\").date()\n",
    "    \n",
    "        #iterate from start to stop dates by day and store dates in list\n",
    "        while start <= stop:\n",
    "            date_list.append(start)\n",
    "            start = start + timedelta(days=1)  # increase day one by one\n",
    "\n",
    "        #convert datetime objects to string\n",
    "        string_list =[d.strftime(\"%Y-%m-%d\") for d in date_list]\n",
    "#         print(string_list)\n",
    "        \n",
    "        for file in filenames: \n",
    "            \n",
    "            # search agreed file format pattern in the filename\n",
    "            for date in string_list: \n",
    "                pattern = r\"\\(\"+date+r\"\\)\\d+\\_\\D+\\_\\d+\\.json\"\n",
    "        \n",
    "                match = re.search(pattern,file)\n",
    "                \n",
    "                #if match is found\n",
    "                if match:\n",
    "                    pattern = os.path.join(path, file) #join path with file name\n",
    "                    file_list.append(pattern) #list of json files that follow the agreed filename\n",
    "\n",
    "        print(\"Files read:\",file_list)     \n",
    "        for file in file_list:\n",
    "            with open(file) as f:\n",
    "                #flatten json into pd dataframe\n",
    "                json_data = pd.json_normalize(json.loads(f.read()))\n",
    "                json_data = pd.DataFrame(json_data)\n",
    "                #label which file each row is from \n",
    "                json_data['file'] = file.rsplit(\"/\", 1)[-1]\n",
    "\n",
    "            df = df.append(json_data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f9fc7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_manipulation(df,col_selection=None,keep=None,subset=None):\n",
    "    \"\"\"\n",
    "    1) Column selection: Keep columns in dataframe\n",
    "    2) Data impute: Impute NA rows with empty string\n",
    "    3) Data duplication cleaning: Drop all duplicates or drop all duplicates except for the first/last occurrence\n",
    "    \n",
    "    params:\n",
    "    df [dataframe]: input dataframe     \n",
    "    col_selection [None/list]: - None [Default]: Keep all columns in dataframe \n",
    "                               - List: List of columns to keep in dataframe                      \n",
    "                                 \n",
    "    keep[None/string/False]: Choose to drop all duplicates or drop all duplicates except for the first/last occurrence\n",
    "                      # - None[DEFAULT] : Drop duplicates except for the first occurrence. \n",
    "                      # - \"last\" : Drop duplicates except for the last occurrence. \n",
    "                      # - False : Drop all duplicates.                 \n",
    "    subset[list/None]: Subset of columns for identifying duplicates, use None if no column to select\n",
    "   \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Shape of df before manipulation:\",df.shape)\n",
    "\n",
    "    #Column selection - user can select column(s) \n",
    "    if col_selection != None:\n",
    "        df = df[col_selection]\n",
    "    \n",
    "    print(\"Shape of df after selecting columns:\",df.shape)\n",
    "\n",
    "    #---Data impute - user can impute or drop rows with NA,freq of null values before & after manipulation returned---#\n",
    "    print(\"Number of null values in df:\\n\",df.isnull().sum())\n",
    "  \n",
    "\n",
    "    # impute NA values with empty string\n",
    "    impute_value = \"\"\n",
    "    df = df.fillna(impute_value)\n",
    "    print(\"Number of null values in df after NA imputation:\\n\",df.isnull().sum())\n",
    "\n",
    "    #---------Data duplication cleaning--------#\n",
    "    print(\"Number of duplicates in the df:\", df.duplicated().sum())\n",
    "\n",
    "    #drop duplicates\n",
    "    if keep==None:\n",
    "        keep=\"first\"\n",
    "    df = df.drop_duplicates(subset=subset, keep=keep)\n",
    "\n",
    "    print(\"Shape of df after manipulation:\",df.shape)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9b747f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_contractions(text):\n",
    "    \"\"\"\n",
    "    Expand word contractions (i.e. \"isn't\" to \"is not\")\n",
    "    params:\n",
    "    text[string]: input string \n",
    "    \"\"\"\n",
    "    import contractions\n",
    "    return \" \".join([contractions.fix(word) for word in text.split()])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d7413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_cont\"] = [word_contractions(text) for text in df[\"title\"]]\n",
    "df[\"desc_cont\"]=  [word_contractions(text) for text in df[\"description\"]]\n",
    "df[\"comments_cont\"]=  [word_contractions(text) for text in df[\"comments\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8574dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase(text):\n",
    "    \"\"\"\n",
    "    Convert all characters to lower case\n",
    "    param:\n",
    "    text[string]: input string \n",
    "    \"\"\"\n",
    "    return text.lower() if type(text) == str else text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc6bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 1: DL -> DP -> Supervised learning\n",
    "# config 2: DL -> DP -> Unsupervised learning\n",
    "# config 3: DL -> DP -> Similarity metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563acb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read config file\n",
    "# import json\n",
    "# json_path = \"C:/Users/nchong/OneDrive - Intel Corporation/Documents/Debug Similarity Analytics and Bucketization Framework/General/\"\n",
    "\n",
    "# with open(json_path+'config.json') as config_file:\n",
    "#     data = json.load(config_file)\n",
    "\n",
    "# path = data[\"DataLoading\"]['path']\n",
    "# start_date = data[\"DataLoading\"]['start_date']\n",
    "# stop_date = data[\"DataLoading\"]['stop_date']\n",
    "# print(path)\n",
    "# print(start_date)\n",
    "# print(stop_date)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
